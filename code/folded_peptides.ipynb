{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folded Peptides\n",
    "This notebook loads in the data generated with AlphaFold2 and apply some machine learning ot it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "module(\"load\",\"cuda/11.2\")\n",
    "module(\"load\",\"tensorflow/gpu-cuda-11.2/2.5.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 20:53:03.493532: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import sklearn.model_selection\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2lebitnd) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 125997... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e99938e5be4ff9ae785c118332a4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">rosy-sponge-17</strong>: <a href=\"https://wandb.ai/jlrestrepol/prot_alphafold2_pep/runs/2lebitnd\" target=\"_blank\">https://wandb.ai/jlrestrepol/prot_alphafold2_pep/runs/2lebitnd</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211130_111326-2lebitnd/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2lebitnd). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-30 11:13:56.257294: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/jlrestrepol/prot_alphafold2_pep/runs/z5emymtn\" target=\"_blank\">decent-cherry-18</a></strong> to <a href=\"https://wandb.ai/jlrestrepol/prot_alphafold2_pep\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/jlrestrepol/prot_alphafold2_pep/runs/z5emymtn?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x14f40a9d6750>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"prot_alphafold2_pep\", entity=\"jlrestrepol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 20:53:09.895689: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-12-01 20:53:10.013841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:31:00.0 name: NVIDIA A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.305GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2021-12-01 20:53:10.013873: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-01 20:53:10.020427: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-12-01 20:53:10.020488: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-12-01 20:53:10.022184: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-12-01 20:53:10.023158: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-12-01 20:53:10.028260: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-12-01 20:53:10.029582: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-12-01 20:53:10.030005: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-12-01 20:53:10.033143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-12-01 20:53:10.033170: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-12-01 20:59:22.146803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-01 20:59:22.146853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-12-01 20:59:22.146862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-12-01 20:59:22.152157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/device:GPU:0 with 38453 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:31:00.0, compute capability: 8.0)\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_list = pd.read_pickle('distance_list.pkl')\n",
    "seq_list = pd.read_pickle('seq_dist_list.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = pd.read_pickle('/u/jrlopez/Fig1_powerlaw.pkl')\n",
    "fig1.loc[:,'Modified sequence'] = fig1['Modified sequence'].str.replace('_', '')\n",
    "fig1_ch2 = fig1[fig1['Charge']==2]\n",
    "fig1_ch2 = fig1_ch2.set_index('Modified sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = fig1_ch2.loc[seq_list,:]['CCS'].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = [tf.convert_to_tensor(e[:,:,np.newaxis], dtype=tf.float32) for e in distance_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [tf.image.convert_image_dtype(tensor, tf.float32) for tensor in tensors]#normalize to (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_std = [tf.image.per_image_standardization(image) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_array = np.array([tf.image.resize(image, (227, 227)) for image in images_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant([[0,1], [2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(a):\n",
    "    \"\"\"Return bottom right padding.\"\"\"\n",
    "    zeros = np.zeros((227,227))\n",
    "    zeros[:a.shape[0], :a.shape[1]] = a\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(a):\n",
    "    mean=np.array([0.485, 0.456, 0.406])\n",
    "    std=np.array([0.229, 0.224, 0.225])\n",
    "    norm = (a-mean[0])/std[0]\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_images = np.array([pad(normalize(a))[:,:,np.newaxis] for a in distance_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 16:43:11.990623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:31:00.0 name: NVIDIA A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.305GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2021-12-01 16:43:11.993698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-12-01 16:43:11.996571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:31:00.0 name: NVIDIA A100-SXM4-40GB computeCapability: 8.0\n",
      "coreClock: 1.305GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s\n",
      "2021-12-01 16:43:11.999578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-12-01 16:43:11.999610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-12-01 16:43:11.999616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-12-01 16:43:11.999619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-12-01 16:43:12.002651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38453 MB memory) -> physical GPU (device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:31:00.0, compute capability: 8.0)\n"
     ]
    }
   ],
   "source": [
    "images_tf = tf.stack(padded_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14d1690b2590>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(padded_images[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/val set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = sk.model_selection.train_test_split(padded_images, labels, test_size = 0.1, random_state = 23112021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "global label_scaler\n",
    "label_scaler = StandardScaler()\n",
    "label_scaler.fit(y_train.reshape(-1, 1))\n",
    "y_train_sc = label_scaler.transform(y_train.reshape(-1, 1))\n",
    "y_val_sc = label_scaler.transform(y_val.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train_sc))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 11211\n",
      "Validation data size: 1246\n"
     ]
    }
   ],
   "source": [
    "train_ds_size = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "validation_ds_size = tf.data.experimental.cardinality(val_ds).numpy()\n",
    "print(\"Training data size:\", train_ds_size)\n",
    "print(\"Validation data size:\", validation_ds_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (train_ds\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=1, drop_remainder=True))\n",
    "\n",
    "val_ds = (val_ds\n",
    "                  .shuffle(buffer_size=train_ds_size)\n",
    "                  .batch(batch_size=1, drop_remainder=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 15:18:25.759693: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-11-25 15:18:25.768644: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2400000000 Hz\n"
     ]
    }
   ],
   "source": [
    "tf.data.experimental.save(train_ds, '../../train_extended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.save(val_ds, '../../val_extended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 12:54:51.613478: E tensorflow/core/framework/dataset.cc:825] Unimplemented: Cannot merge options for dataset of type LoadDataset, because the dataset does not implement `InputDatasets`.\n",
      "2021-12-01 12:54:51.701579: E tensorflow/core/framework/dataset.cc:825] Unimplemented: Cannot merge options for dataset of type LoadDataset, because the dataset does not implement `InputDatasets`.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.experimental.load('../../train_extended', tf.TensorSpec(shape=(None,227,227,1), dtype=tf.float32))\n",
    "val_ds = tf.data.experimental.load('../../val_extended', tf.TensorSpec(shape=(None,227,227,1), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train[:,:,:,np.newaxis]\n",
    "#x_val = x_val[:,:,:,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing library\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4206.747604309568"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_val)\n",
    "mean_squared_error(pred*59.36563519+414.34814871, y_val_sc*59.36563519+414.34814871)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_scaled(y_true, y_pred):\n",
    "    labels = y_true\n",
    "    preds = y_pred\n",
    "    preds_scaled = preds*59.36563519+414.34814871\n",
    "    labels_scaled = labels*59.36563519+414.34814871\n",
    "    mse_scaled = K.mean(K.square(preds_scaled - labels_scaled), axis=-1)\n",
    "    return mse_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mpcdf/soft/SLE_15/packages/skylake/tensorflow/gpu-cuda-11.2/anaconda_3_2020.02-2020.02/2.5.0/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"mean_squared_error\", optimizer=tf.optimizers.SGD(lr=0.001, clipnorm = 1), metrics=[mse_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(y_val, (y_val_sc*59.36563519+414.34814871).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "11211/11211 [==============================] - 128s 11ms/step - loss: 4.5616 - mse_scaled: 16076.2783 - val_loss: 0.5478 - val_mse_scaled: 1930.6443\n",
      "Epoch 2/4\n",
      "11211/11211 [==============================] - 125s 11ms/step - loss: 1.0776 - mse_scaled: 3797.8911 - val_loss: 0.5516 - val_mse_scaled: 1944.0249\n",
      "Epoch 3/4\n",
      " 4535/11211 [===========>..................] - ETA: 1:10 - loss: 0.4622 - mse_scaled: 1628.7468"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44988/2223406660.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_15/packages/skylake/tensorflow/gpu-cuda-11.2/anaconda_3_2020.02-2020.02/2.5.0/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_15/packages/skylake/tensorflow/gpu-cuda-11.2/anaconda_3_2020.02-2020.02/2.5.0/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_15/packages/skylake/tensorflow/gpu-cuda-11.2/anaconda_3_2020.02-2020.02/2.5.0/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_15/packages/skylake/tensorflow/gpu-cuda-11.2/anaconda_3_2020.02-2020.02/2.5.0/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_15/packages/skylake/tensorflow/gpu-cuda-11.2/anaconda_3_2020.02-2020.02/2.5.0/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mpcdf/soft/SLE_15/packages/skylake/tensorflow/gpu-cuda-11.2/anaconda_3_2020.02-2020.02/2.5.0/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/mpcdf/soft/SLE_15/packages/skylake/tensorflow/gpu-cuda-11.2/anaconda_3_2020.02-2020.02/2.5.0/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, epochs = 4, validation_data=val_ds, validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "350/350 [==============================] - 9s 18ms/step - loss: 127721.0859 - val_loss: 105669.3125\n",
      "Epoch 2/20\n",
      "350/350 [==============================] - 7s 17ms/step - loss: 21134.7461 - val_loss: 16577.3066\n",
      "Epoch 3/20\n",
      "350/350 [==============================] - 8s 20ms/step - loss: 1801.8323 - val_loss: 2032.1055\n",
      "Epoch 4/20\n",
      "350/350 [==============================] - 8s 21ms/step - loss: 1411.9485 - val_loss: 1048.4812\n",
      "Epoch 5/20\n",
      "350/350 [==============================] - 9s 20ms/step - loss: 1295.3125 - val_loss: 750.4927\n",
      "Epoch 6/20\n",
      "350/350 [==============================] - 8s 20ms/step - loss: 1140.7584 - val_loss: 788.6707\n",
      "Epoch 7/20\n",
      "350/350 [==============================] - 7s 19ms/step - loss: 1081.2740 - val_loss: 588.1708\n",
      "Epoch 8/20\n",
      "350/350 [==============================] - 7s 17ms/step - loss: 1011.1448 - val_loss: 847.0958\n",
      "Epoch 9/20\n",
      "350/350 [==============================] - 7s 19ms/step - loss: 967.5139 - val_loss: 586.5483\n",
      "Epoch 10/20\n",
      "350/350 [==============================] - 8s 20ms/step - loss: 954.8596 - val_loss: 747.8902\n",
      "Epoch 11/20\n",
      "350/350 [==============================] - 9s 21ms/step - loss: 905.4894 - val_loss: 505.3300\n",
      "Epoch 12/20\n",
      "350/350 [==============================] - 7s 17ms/step - loss: 880.9760 - val_loss: 504.3260\n",
      "Epoch 13/20\n",
      "350/350 [==============================] - 7s 19ms/step - loss: 847.3666 - val_loss: 516.9019\n",
      "Epoch 14/20\n",
      "350/350 [==============================] - 7s 19ms/step - loss: 843.9692 - val_loss: 502.5206\n",
      "Epoch 15/20\n",
      "350/350 [==============================] - 6s 17ms/step - loss: 829.5204 - val_loss: 520.9376\n",
      "Epoch 16/20\n",
      "350/350 [==============================] - 7s 18ms/step - loss: 802.8618 - val_loss: 616.8519\n",
      "Epoch 17/20\n",
      "350/350 [==============================] - 8s 20ms/step - loss: 780.9928 - val_loss: 598.1726\n",
      "Epoch 18/20\n",
      "350/350 [==============================] - 9s 21ms/step - loss: 771.8511 - val_loss: 752.5809\n",
      "Epoch 19/20\n",
      "350/350 [==============================] - 8s 20ms/step - loss: 742.5593 - val_loss: 580.3948\n",
      "Epoch 20/20\n",
      "350/350 [==============================] - 8s 19ms/step - loss: 724.4440 - val_loss: 826.7184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x153b70b85e50>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs = 20, validation_data=val_ds, validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(lr=0.001)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "val_metric = tf.keras.metrics.MeanSquaredError()\n",
    "train_metric = tf.keras.metrics.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0. Training\n",
      "Epoch loss = 7.727229595184326. Validation loss = 1.533576488494873\n",
      "epoch 1. Training\n",
      "Epoch loss = 4.92893648147583. Validation loss = 0.8822929859161377\n",
      "epoch 2. Training\n",
      "Epoch loss = 3.4323785305023193. Validation loss = 0.7458745837211609\n",
      "epoch 3. Training\n",
      "Epoch loss = 2.3716514110565186. Validation loss = 0.7020072340965271\n",
      "epoch 4. Training\n",
      "Epoch loss = 1.7719653844833374. Validation loss = 0.6269655227661133\n",
      "epoch 5. Training\n",
      "Epoch loss = 1.331405520439148. Validation loss = 0.5953965783119202\n",
      "epoch 6. Training\n",
      "Epoch loss = 0.9879685044288635. Validation loss = 0.675258457660675\n",
      "epoch 7. Training\n",
      "Epoch loss = 0.7705870866775513. Validation loss = 0.6097710132598877\n",
      "epoch 8. Training\n",
      "Epoch loss = 0.5831345915794373. Validation loss = 0.5233178734779358\n",
      "epoch 9. Training\n",
      "Epoch loss = 0.4791673719882965. Validation loss = 0.5908235907554626\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for epoch in np.arange(10):\n",
    "    print(f\"epoch {epoch}. Training\")\n",
    "\n",
    "    # get trainable variables\n",
    "    train_vars = model.trainable_variables\n",
    "    # Create empty gradient list (not a tf.Variable list)\n",
    "    accum_gradient = [tf.zeros_like(this_var) for this_var in train_vars]\n",
    "    total_loss = 0\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_ds):\n",
    "        #image = image[np.newaxis,:,:,:].astype(\"float32\")\n",
    "        #label = np.array(label).reshape(1,-1).astype(\"float32\")\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training = True)\n",
    "            logits = logits[0]\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "            total_loss += loss_value\n",
    "        grads = tape.gradient(loss_value, train_vars)\n",
    "        ##grads = [tf.clip_by_norm(grad, 2) for grad in grads]\n",
    "        #grads = tf.clip_by_global_norm(grads, 1.0) for grad in grads]\n",
    "        #optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        train_metric.update_state(y_batch_train, logits)\n",
    "        # Accumulate the gradients\n",
    "        accum_gradient = [(acum_grad+grad) for acum_grad, grad in zip(accum_gradient, grads)]\n",
    "        \n",
    "\n",
    "        if (step%batch_size==0) or (len(x_train) - step == 1):\n",
    "            accum_gradient = [tf.clip_by_norm(grad, 1) for grad in accum_gradient]\n",
    "            #accum_gradient = [this_grad/batch_size for this_grad in accum_gradient]\n",
    "            optimizer.apply_gradients(zip(accum_gradient, model.trainable_variables), experimental_aggregate_gradients=False)            \n",
    "            # Create empty gradient list (not a tf.Variable list)\n",
    "            train_vars = model.trainable_variables\n",
    "            accum_gradient = [tf.zeros_like(this_var) for this_var in train_vars]\n",
    "            \n",
    "            continue\n",
    "    \n",
    "    error_train = train_metric.result()\n",
    "    train_metric.reset_states()\n",
    "\n",
    "    predicted = np.zeros_like(y_val, dtype = \"float32\")\n",
    "    for j, (x_batch_val, y_batch_val) in enumerate(val_ds):\n",
    "        #image = image[np.newaxis,:,:,:].astype(\"float32\")\n",
    "        val_logits = model(x_batch_val, training = False)\n",
    "        val_metric.update_state(val_logits, y_batch_val)\n",
    "    error = val_metric.result()\n",
    "    val_metric.reset_states()\n",
    "\n",
    "    print(f'Epoch loss = {error_train}. Validation loss = {error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = np.array(list(map(lambda x: x.shape[0], distance_list)))\n",
    "idx = [e >= 9 for e in shapes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_sublist = np.array(distance_list, dtype=object)[idx].tolist()\n",
    "labels_sublist = labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../sublist.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(distance_sublist, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../sublabels.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(labels_sublist, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load-in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../sublist.pkl\", \"rb\") as handle:\n",
    "    distance_sublist = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../sublabels.pkl\", \"rb\") as handle:\n",
    "    labels_sublist = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = sk.model_selection.train_test_split(distance_sublist, labels_sublist, test_size = 0.1, random_state = 23112021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_scaler.fit(y_train.reshape(-1, 1))\n",
    "y_train_sc = label_scaler.transform(y_train.reshape(-1, 1))\n",
    "y_val_sc = label_scaler.transform(y_val.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flat = np.hstack([e.flatten() for e in x_train])\n",
    "x_mean = np.mean(train_flat)\n",
    "x_std = np.std(train_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sc = list(map(lambda x : (x - x_mean)/x_std, x_train))\n",
    "x_val_sc = list(map(lambda x : (x - x_mean)/x_std, x_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def FCN_model(len_classes=1, dropout_rate=0.5):\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(None, None, 1))\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)(inputs)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=1)(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=1)(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "    #x = tf.keras.layers.Conv2D(filters=512, kernel_size=3, strides=2)(x)\n",
    "    #x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    #x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # Uncomment the below line if you're using dense layers\n",
    "    # x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Fully connected layer 1\n",
    "    # x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    # x = tf.keras.layers.BatchNormalization()(x)\n",
    "    # x = tf.keras.layers.Dense(units=64)(x)\n",
    "    # x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # Fully connected layer 1\n",
    "    x = tf.keras.layers.Conv2D(filters=64, kernel_size=1, strides=1)(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # Fully connected layer 2\n",
    "    # x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    # x = tf.keras.layers.BatchNormalization()(x)\n",
    "    # x = tf.keras.layers.Dense(units=len_classes)(x)\n",
    "    # predictions = tf.keras.layers.Activation('softmax')(x)\n",
    "\n",
    "    # Fully connected layer 2\n",
    "    x = tf.keras.layers.Conv2D(filters=len_classes, kernel_size=1, strides=1)(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    #x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "    predictions = tf.keras.layers.Activation('linear')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "    \n",
    "    #print(model.summary())\n",
    "    print(f'Total number of layers: {len(model.layers)}')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, None, None, 1)]   0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, None, 32)    320       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 64)    18496     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, None, None, 64)    16448     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, None, None, 1)     65        \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 404,353\n",
      "Trainable params: 404,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Total number of layers: 20\n"
     ]
    }
   ],
   "source": [
    "fcn = FCN_model()\n",
    "fcn.compile(loss = \"mean_squared_error\", optimizer= tf.keras.optimizers.Adam(lr=0.0001, clipnorm = 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, matrices, labels, BATCH_SIZE=1, shuffle_images=True, image_min_side=24):\n",
    "        \"\"\" Initialize Generator object.\n",
    "        Args\n",
    "            DATASET_PATH           : Path to folder containing individual folders named by their class names\n",
    "            BATCH_SIZE             : The size of the batches to generate.\n",
    "            shuffle_images         : If True, shuffles the images read from the DATASET_PATH\n",
    "            image_min_side         : After resizing the minimum side of an image is equal to image_min_side.\n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.shuffle_images = shuffle_images\n",
    "        self.image_groups = matrices\n",
    "        self.label_groups = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of batches for generator.\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.image_groups)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Keras sequence method for generating batches.\n",
    "        \"\"\"\n",
    "        label_group = np.array(self.label_groups[index]).reshape(1,-1)\n",
    "        images = [self.image_groups[index][:,:,np.newaxis]]\n",
    "        image_batch = np.zeros((self.batch_size,)+images[0].shape)\n",
    "        for image_index, image in enumerate(images):\n",
    "            image_batch[image_index, :image.shape[0], :image.shape[1], :image.shape[2]] = image\n",
    "\n",
    "        return image_batch, label_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = Generator(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = Generator(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10438/10438 [==============================] - 106s 10ms/step - loss: 143.8248 - val_loss: 129.7308\n",
      "Epoch 2/20\n",
      "10438/10438 [==============================] - 106s 10ms/step - loss: 136.8429 - val_loss: 129.7198\n",
      "Epoch 3/20\n",
      "10438/10438 [==============================] - 106s 10ms/step - loss: 138.5665 - val_loss: 129.7310\n",
      "Epoch 4/20\n",
      "10438/10438 [==============================] - 105s 10ms/step - loss: 138.7012 - val_loss: 129.6603\n",
      "Epoch 5/20\n",
      "10438/10438 [==============================] - 106s 10ms/step - loss: 144.8352 - val_loss: 129.7163\n",
      "Epoch 6/20\n",
      "10438/10438 [==============================] - 106s 10ms/step - loss: 140.4478 - val_loss: 129.7362\n",
      "Epoch 7/20\n",
      "10438/10438 [==============================] - 106s 10ms/step - loss: 135.2414 - val_loss: 129.7063\n",
      "Epoch 8/20\n",
      "10438/10438 [==============================] - 106s 10ms/step - loss: 138.9927 - val_loss: 128.1890\n",
      "Epoch 9/20\n",
      "10438/10438 [==============================] - 105s 10ms/step - loss: 138.7748 - val_loss: 127.6629\n",
      "Epoch 10/20\n",
      "10438/10438 [==============================] - 105s 10ms/step - loss: 134.4696 - val_loss: 127.8346\n",
      "Epoch 11/20\n",
      "10438/10438 [==============================] - 102s 10ms/step - loss: 140.1370 - val_loss: 127.3469\n",
      "Epoch 12/20\n",
      "10438/10438 [==============================] - 95s 9ms/step - loss: 136.2854 - val_loss: 127.8274\n",
      "Epoch 13/20\n",
      "10438/10438 [==============================] - 95s 9ms/step - loss: 137.1977 - val_loss: 127.6893\n",
      "Epoch 14/20\n",
      "10438/10438 [==============================] - 95s 9ms/step - loss: 135.3942 - val_loss: 127.6031\n",
      "Epoch 15/20\n",
      "10438/10438 [==============================] - 95s 9ms/step - loss: 134.3044 - val_loss: 127.5238\n",
      "Epoch 16/20\n",
      "10438/10438 [==============================] - 95s 9ms/step - loss: 138.6061 - val_loss: 127.5763\n",
      "Epoch 17/20\n",
      "  875/10438 [=>............................] - ETA: 1:22 - loss: 142.9396"
     ]
    }
   ],
   "source": [
    "history = fcn.fit(train_generator, epochs = 20, validation_data = val_generator, steps_per_epoch=len(train_generator), validation_steps=len(val_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loop from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mpcdf/soft/SLE_15/packages/skylake/tensorflow/gpu-cuda-11.2/anaconda_3_2020.02-2020.02/2.5.0/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "fcn = FCN_model()\n",
    "optimizer = tf.optimizers.SGD(lr=0.001)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "val_metric = tf.keras.metrics.MeanSquaredError()\n",
    "train_metric = tf.keras.metrics.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The initial validation error is 0.9747118949890137'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = np.zeros_like(y_val_sc, dtype = \"float32\")\n",
    "for j, (image, label) in enumerate(zip(x_val_sc, y_val_sc)):\n",
    "    image = image[np.newaxis,:,:,np.newaxis].astype(\"float32\")\n",
    "    predicted[j] = fcn(image, training = False)\n",
    "error = loss_fn(predicted, y_val_sc).numpy()\n",
    "f'The initial validation error is {error}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0. Training\n",
      "Epoch loss = 0.5463468432426453. Validation loss = 0.4894874691963196\n",
      "epoch 1. Training\n",
      "Epoch loss = 0.45629915595054626. Validation loss = 0.4871244728565216\n",
      "epoch 2. Training\n",
      "Epoch loss = 0.43855020403862. Validation loss = 0.44011732935905457\n",
      "epoch 3. Training\n",
      "Epoch loss = 0.43151620030403137. Validation loss = 0.5166045427322388\n",
      "epoch 4. Training\n",
      "Epoch loss = 0.427420437335968. Validation loss = 0.4463052749633789\n",
      "epoch 5. Training\n",
      "Epoch loss = 0.4262346923351288. Validation loss = 0.47982046008110046\n",
      "epoch 6. Training\n",
      "Epoch loss = 0.41545259952545166. Validation loss = 0.4424302279949188\n",
      "epoch 7. Training\n",
      "Epoch loss = 0.4245167076587677. Validation loss = 0.43822750449180603\n",
      "epoch 8. Training\n",
      "Epoch loss = 0.42620664834976196. Validation loss = 0.4489021599292755\n",
      "epoch 9. Training\n",
      "Epoch loss = 0.41744551062583923. Validation loss = 0.45573294162750244\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for epoch in np.arange(10):\n",
    "    print(f\"epoch {epoch}. Training\")\n",
    "    total_loss = 0\n",
    "\n",
    "    # get trainable variables\n",
    "    train_vars = fcn.trainable_variables\n",
    "    # Create empty gradient list (not a tf.Variable list)\n",
    "    accum_gradient = [tf.zeros_like(this_var) for this_var in train_vars]\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(zip(x_train_sc, y_train_sc)):\n",
    "        x_batch_train = x_batch_train[np.newaxis,:,:,np.newaxis].astype(\"float64\")\n",
    "        y_batch_train = np.array([y_batch_train]).astype(\"float64\")\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = fcn(x_batch_train, training = True)\n",
    "            logits = logits[0]\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "            total_loss += loss_value\n",
    "        grads = tape.gradient(loss_value, train_vars)\n",
    "        ##grads = [tf.clip_by_norm(grad, 1.0) for grad in grads]\n",
    "        # Accumulate the gradients\n",
    "        train_metric.update_state(y_batch_train, logits)\n",
    "        accum_gradient = [(acum_grad+grad) for acum_grad, grad in zip(accum_gradient, grads)]\n",
    "        \n",
    "        if (step%batch_size==0) or (len(x_train_sc) - step == 1):\n",
    "            grads = [tf.clip_by_norm(grad, 5) for grad in accum_gradient]\n",
    "            #accum_gradient = [this_grad/batch_size for this_grad in accum_gradient]\n",
    "            optimizer.apply_gradients(zip(accum_gradient, fcn.trainable_variables), experimental_aggregate_gradients=False)\n",
    "\n",
    "            # Create empty gradient list (not a tf.Variable list)\n",
    "            train_vars = fcn.trainable_variables\n",
    "            accum_gradient = [tf.zeros_like(this_var) for this_var in train_vars]\n",
    "            continue\n",
    "    \n",
    "    error_train = train_metric.result()\n",
    "    train_metric.reset_states()        \n",
    "\n",
    "    predicted = np.zeros_like(y_val, dtype = \"float32\")\n",
    "    for j, (x_batch_val, y_batch_val) in enumerate(zip(x_val_sc, y_val_sc)):\n",
    "        x_batch_val = x_batch_val[np.newaxis,:,:,np.newaxis].astype(\"float32\")\n",
    "        val_logits = fcn(x_batch_val, training = False)\n",
    "        val_metric.update_state(val_logits, y_batch_val)\n",
    "    error = val_metric.result()\n",
    "    val_metric.reset_states()\n",
    "    \n",
    "    print(f'Epoch loss = {error_train}. Validation loss = {error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ccs)",
   "language": "python",
   "name": "ccs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
